---
title: "Patrones puntuales"
author: 
  - "Juan José Galeano Arenas"
  - "Juan Sebastián Mendoza Páez"
  - "Germán Alonso Patiño Hurtado"
date: '2022-06-05'
output:
  html_document:
    code_folding: hide
    theme: readable
---

```{r message=FALSE, warning=FALSE}
library(RSocrata)
library(tidyverse)
library(lubridate)
library(tidygeocoder)
library(rgeoboundaries)
library(sf)
library(tmap)
library(spatstat)
source("Funciones_propias_ppp.R", encoding = "UTF-8")
```

# Contextualización

La accidentalidad es uno de los problemas más comunes en el planeta provocando perdidas que pueden ir desde materiales hasta la vida misma, por lo que es de particular interés tratar de comprender como se comporta este fenómeno para evitar ser victimas de él. 

La problemática en cuestión tiene la complicación de ser algo de naturaleza aleatoria, sin embargo esto no quiere decir que no exista alguna forma de controlarla pues la experiencia ha mostrado que las diferentes ciudades tienen lugares con mayor concentración de accidentes que otras ubicaciones dentro de la misma ciudad.

Debido a que se está trabajando la ocurrencia de accidentes en una ciudad de interés, la distribución Poisson y los procesos puntuales Poisson resultan ser una herramienta adecuada para tratar de explicar el fenómeno.

# Obtención de la base de datos

Una vez presentado el fenómeno que se trabajará, se selecciona la ciudad de Barranquilla para realizar el estudio. 

Los datos se extrajeron de la página web GOV.CO la cual tiene diferentes bases da datos de Colombia abiertas al público. (<a href="https://www.datos.gov.co/Transporte/Accidentalidad-en-Barranquilla/yb9r-2dsi/data"> Accidentalidad en Barranquilla</a>). La base de datos contiene una gran cantidad de variables, sin embargo solo se escogen aquellas de interés para el patrón puntual. La estructura de los datos es presentada a continuación:

```{r}
accidentes <- read.socrata("https://www.datos.gov.co/resource/yb9r-2dsi.json") %>%
    mutate(fecha = ymd(fecha_accidente)) %>%
    select(12, 6:8) %>%
    filter(year(fecha) == 2021)
knitr::kable(head(accidentes, 10),
             col.names = c("Fecha", "Gravedad del accidentes",
                           "Clase de accidentes", "Sitio accidente"))
```

# Geocodificación de las direcciones

Se hace necesario realizarle unos ajustes a la base de datos considerada puesto que está no incluye las ubicaciones exactas de los accidentes ya sea en longitud - latitud o proyección UTM, para dicho propósito se usa la función `geo()` del paquete `tidygeocoder` para convertir las direcciones de los accidentes en coordenadas de longitud - latitud. 

```{r eval=FALSE, include=TRUE}
# NO CORRER ESTE CHUNK
direcciones <- paste(accidentes$sitio_exacto_accidente, ", Barranquilla, Colombia", sep = "")
localizaciones <- geo(address = direcciones, method = "arcgis")
write.csv(x = localizaciones, file = "accidentes.csv", row.names = F)
```

Luego de realizar obtener las coordenadas en longitud - latitud, se usan múltiples funciones del paquete `sf` para obtener las respectivas ubicaciones en formato UTM obteniéndose lo siguiente:

```{r message=FALSE, warning=FALSE}
bqlla <- geoboundaries(country = "COLOMBIA", adm_lvl = 2) %>%
    filter(shapeName ==
             "DISTRITO ESPECIAL, INDUSTRIAL Y PORTUARIO DE BARR*") %>%
    st_transform(crs = 3857)

coordenadas <- read.csv("accidentes.csv")

# Se toman 1as primeras 4700 filas para no tener que regenerar el csv
# de localizaciones
accidentes_sf <- cbind(accidentes, coordenadas[8927:13626, 2:3]) %>%
  st_as_sf(coords = c('long', 'lat')) %>%
  st_set_crs(value = 4326) %>%
  st_transform(crs = 3857) %>%
  st_intersection(bqlla) %>% 
  filter(gravedad_accidente == "Con heridos") %>% 
  select(-fecha, -gravedad_accidente)

knitr::kable(head(accidentes_sf[, c(1:2, 8)], 10))
```

# Gráfico de las localizaciones 

```{r ubicaciones, message=FALSE, warning=FALSE, fig.align='center'}
tmap_mode('view')

tm_shape(bqlla)+
  tm_polygons(alpha = 0.3, border.alpha = 0.7)+
  tm_shape(shp = accidentes_sf)+
  tm_dots(size = 0.01)
```

# Pruebas de homogeneidad en la intensidad

Uno de los parámetros críticos al momento de modelar un patrón puntual es la intensidad la cual puede ser constante (homogénea) o variable (inhomogénea), por lo tanto es importante iniciar el análisis con una prueba de homogeneidad de la intensidad.

```{r message=FALSE, warning=FALSE, fig.height=8}
# Definiendo el patron puntual de los datos
datos_ppp <- ppp(x = st_coordinates(accidentes_sf)[, 1],
             y = st_coordinates(accidentes_sf)[, 2],
             window = as.owin(W = bqlla))
```

## Argumento gráfico {.tabset .tabset-fade .tabset-pills}

Para iniciar, se divide el mapa de Barranquilla en 25 cuadrantes, si el patrón fuera homogéneo se esperaría que el número de accidentes en cada uno de las subsecciones de la ciudad contenga aproximadamente la misma cantidad de accidentes.

```{r}
qc_datos <- quadratcount(datos_ppp, nx = 5, ny = 5)
plot(qc_datos, main = "Accidentes en 2021")
```

Se aprecia que existe discrepancia entre el número de accidentes por sectores. Claramente al este de la ciudad el número de accidentes es mayor respecto al oeste lo cual es señal de que el patrón puntual en cuestión es de naturaleza inhomogénea.

## Prueba $\chi^2$ {.tabset .tabset-fade .tabset-pills}

Adicional a los conteos del número de accidentes en cada uno de los sectores definidos previamente, se usa la prueba $\chi^2$ para contrastar:

$$
\begin{cases}
H_0: \text{La intensidad es constante} \\
H_1: \text{La intensidad no es constante}
\end{cases}
$$
A continuación se muestra el resultado obtenido

```{r warning = F}
quadrat.test(qc_datos)
```

Puesto que se tiene un valor - p demasiado pequeño (orden de $10^{-16}$) se rechaza la hipótesis de homogeneidad de intensidad, es decir, la intensidad puede ser modelada mediante una relación funcional $\lambda(x,y)$ y se hace necesario estimarla con algún método ya sea paramétrico o no paramétrico como se vera más adelante.

# Estimación de propiedades de primer orden

Previamente se verifico que el número de accidentes en la ciudad tiene intensidad inhomogénea, en esta sección el propósito es estimar dicha función ya sea con metodología paramétrica y no paramética

# No paramétrica {.tabset .tabset-fade .tabset-pills}

A continuación se presentan mapas de probabilidad de accidentalidad al realizar una estimación no paramétrica de la función de intensidad basado en funciones kernel los cuales son de la forma:

$$
\hat{\lambda}(x) = \frac{1}{h^2} \sum_{i = 1}^{n} \frac{\kappa\left(\frac{||x-x_i||}{h}\right)}{q(||x||)}
$$

La selección del ancho de banda se puede escoger de muchas maneras y existen múltiples métodos para calcularlos. Luego de usar diferentes propuestas para el calculo de este y probar con valores empíricos se llego a que un valor razonable para el mismo es 350 pues captura la concentración de accidentes de forma plausible.

```{r}
graph_ppp(datos_ppp, 550, "Año 2021")
```

# Estimación de propiedad de primer orden usando modelos log-lineales

usando modelos log-lineales los cuales son de la forma

$$
log \ \lambda_\theta (u) = \theta \cdot S(u) 
$$

donde $S(u)$ es una función vectorial de valor real evaluada en alguna ubicación $u$. 

Para ajustar estos modelos en R, se usan la función `ppm()` del paquete `spatstat` la cual recibe como primer argumento un objeto de la clase `ppp` y como segundo una formula.

El ajuste de dichos es modelos es sensible a la escala de medición de las ubicaciones; debido a que las ubicaciones se encuentran en metros (los cuales son números muy grandes) es necesario cambiar la escala de medición por una más "pequeña" para evitar problemas de singularidad matricial por lo que se convierten los metros en kilometros.
 
```{r rescalando-datos}
# Rescalando los objetos ppp para ajustar los modelos
# Ano 2019
datos_2019 <- rescale(datos_2019, 1000)
unitname(datos_2019) <- c("km", "kilometers")

# Ano 2020
datos_2020 <- rescale(datos_2020, 1000)
unitname(datos_2020) <- c("km", "kilometers")

# Ano 2021
datos_2021 <- rescale(datos_2021, 1000)
unitname(datos_2021) <- c("km", "kilometers") 
```

Luego de reescalar las ubicaciones se ajustan algunos modelos log-lineales.

```{r warning=F}
# Ajuste de modelos
# Tendencia lineal en x e y
log_lin_2019 <- ppm(datos_2019, ~ x + y)
log_lin_2020 <- ppm(datos_2020, ~ x + y)
log_lin_2021 <- ppm(datos_2021, ~ x + y)
```











